{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6121f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 2.4/7.0 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 20.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-11.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5084bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "metadata_file = 'HAM10000_metadata.csv'\n",
    "images_dir = 'all_images'         # Folder with all extracted .jpg files\n",
    "output_base = 'data'              # Where to make train/val folders\n",
    "\n",
    "# Create train/val folders and class subfolders\n",
    "classes = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "for split in ['train', 'val']:\n",
    "    for cls in classes:\n",
    "        os.makedirs(os.path.join(output_base, split, cls), exist_ok=True)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a83cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 8012/8012 [01:29<00:00, 89.10it/s] \n",
      "Processing val: 100%|██████████| 2003/2003 [00:24<00:00, 80.29it/s] \n"
     ]
    }
   ],
   "source": [
    "# Read metadata\n",
    "df = pd.read_csv(metadata_file)\n",
    "\n",
    "# Stratified split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['dx'], random_state=42)\n",
    "\n",
    "    # Function to copy images into subfolders\n",
    "def copy_images(sub_df, split):\n",
    "    for _, row in tqdm(sub_df.iterrows(), total=len(sub_df), desc=f'Processing {split}'):\n",
    "        fname = row['image_id'] + '.jpg'\n",
    "        label = row['dx']\n",
    "        src = os.path.join(images_dir, fname)\n",
    "        dst = os.path.join(output_base, split, label, fname)\n",
    "        if os.path.exists(src):\n",
    "            shutil.copy(src, dst)\n",
    "# Run the automation\n",
    "copy_images(train_df, 'train')\n",
    "copy_images(val_df, 'val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ea08cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 images belonging to 7 classes.\n",
      "Found 2003 images belonging to 7 classes.\n",
      "Epoch 1/10\n",
      "251/251 [==============================] - 202s 771ms/step - loss: 1.0433 - accuracy: 0.6665 - val_loss: 0.8037 - val_accuracy: 0.7089\n",
      "Epoch 2/10\n",
      "251/251 [==============================] - 117s 467ms/step - loss: 0.8511 - accuracy: 0.7096 - val_loss: 0.7616 - val_accuracy: 0.7189\n",
      "Epoch 3/10\n",
      "251/251 [==============================] - 115s 459ms/step - loss: 0.8011 - accuracy: 0.7224 - val_loss: 0.7580 - val_accuracy: 0.7299\n",
      "Epoch 4/10\n",
      "251/251 [==============================] - 116s 462ms/step - loss: 0.7776 - accuracy: 0.7223 - val_loss: 0.7448 - val_accuracy: 0.7324\n",
      "Epoch 5/10\n",
      "251/251 [==============================] - 116s 460ms/step - loss: 0.7600 - accuracy: 0.7279 - val_loss: 0.7265 - val_accuracy: 0.7439\n",
      "Epoch 6/10\n",
      "251/251 [==============================] - 120s 476ms/step - loss: 0.7409 - accuracy: 0.7353 - val_loss: 0.7340 - val_accuracy: 0.7369\n",
      "Epoch 7/10\n",
      "251/251 [==============================] - 116s 464ms/step - loss: 0.7315 - accuracy: 0.7368 - val_loss: 0.7281 - val_accuracy: 0.7444\n",
      "Epoch 8/10\n",
      "251/251 [==============================] - 115s 457ms/step - loss: 0.7311 - accuracy: 0.7368 - val_loss: 0.7232 - val_accuracy: 0.7449\n",
      "Epoch 9/10\n",
      "251/251 [==============================] - 115s 459ms/step - loss: 0.7245 - accuracy: 0.7386 - val_loss: 0.7153 - val_accuracy: 0.7419\n",
      "Epoch 10/10\n",
      "251/251 [==============================] - 116s 460ms/step - loss: 0.7266 - accuracy: 0.7396 - val_loss: 0.7027 - val_accuracy: 0.7454\n",
      "✅ Model trained and saved to skin_model.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import PIL\n",
    "# Load training data\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ").flow_from_directory('data/train', target_size=(224,224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "# Load validation data\n",
    "val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    'data/val', target_size=(224,224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "# Base model\n",
    "base = tf.keras.applications.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "base.trainable = False\n",
    "\n",
    "# Add head\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base.output)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "output = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=base.input, outputs=output)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=10)\n",
    "\n",
    "# Save\n",
    "model.save('skin_model.h5')\n",
    "print(\"✅ Model trained and saved to skin_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe36fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "251/251 [==============================] - 127s 492ms/step - loss: 1.0604 - accuracy: 0.6618 - val_loss: 0.8394 - val_accuracy: 0.7399\n",
      "Epoch 2/5\n",
      "251/251 [==============================] - 125s 499ms/step - loss: 0.8906 - accuracy: 0.7008 - val_loss: 0.8786 - val_accuracy: 0.7439\n",
      "Epoch 3/5\n",
      "251/251 [==============================] - 127s 504ms/step - loss: 0.8304 - accuracy: 0.7157 - val_loss: 0.8536 - val_accuracy: 0.7474\n",
      "Epoch 4/5\n",
      "251/251 [==============================] - 127s 505ms/step - loss: 0.7594 - accuracy: 0.7346 - val_loss: 0.8382 - val_accuracy: 0.7524\n",
      "Epoch 5/5\n",
      "251/251 [==============================] - 129s 512ms/step - loss: 0.7326 - accuracy: 0.7395 - val_loss: 0.7970 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25749f7fd60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.trainable = True\n",
    "for layer in base.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402f2e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('skin_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab19c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
